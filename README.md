# ğŸ‡«ğŸ‡· Fine-tuning GPT-2 FranÃ§ais avec Nanochat

Tutorial complet pour fine-tuner le modÃ¨le GPT-2 franÃ§ais (`asi/gpt-fr-cased-base`) sur vos propres donnÃ©es, directement dans Google Colab avec un GPU gratuit.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/VOTRE-USERNAME/nanochat-french-tutorial/blob/main/nanochat_french_colab.ipynb)

## ğŸ¯ Objectif

Ce notebook vous guide pas Ã  pas pour :
- âœ… Fine-tuner GPT-2 franÃ§ais sur vos dialogues personnalisÃ©s
- âœ… Utiliser un GPU gratuit (Google Colab T4)
- âœ… Obtenir un modÃ¨le personnalisÃ© en 15-20 minutes
- âœ… TÃ©lÃ©charger votre modÃ¨le pour l'utiliser localement

## ğŸ“‹ PrÃ©requis

1. **Un compte Google** (pour accÃ©der Ã  Google Colab)
2. **Un dataset de dialogues** au format JSONL (voir section [Format du dataset](#format-du-dataset))
3. **15-20 minutes** de votre temps

Aucune installation locale requise ! Tout se fait dans le navigateur.

## ğŸš€ DÃ©marrage rapide

### Option 1 : Utiliser le notebook Colab (RecommandÃ©)

1. Cliquez sur le badge "Open in Colab" ci-dessus
2. **Runtime** â†’ **Change runtime type** â†’ SÃ©lectionnez **T4 GPU**
3. Suivez les instructions cellule par cellule
4. Uploadez votre dataset quand demandÃ©
5. Lancez le training !

### Option 2 : Cloner et adapter localement

```bash
git clone https://github.com/VOTRE-USERNAME/nanochat-french-tutorial.git
cd nanochat-french-tutorial

# Ouvrir le notebook dans Jupyter/VSCode
jupyter notebook nanochat_french_colab.ipynb
```

## ğŸ“Š Format du dataset

Votre fichier `combined_dataset.jsonl` doit contenir des dialogues au format suivant :

```jsonl
{"messages": [{"role": "user", "content": "Bonjour, comment allez-vous ?"}, {"role": "assistant", "content": "Je vais bien, merci ! Et vous ?"}]}
{"messages": [{"role": "user", "content": "Expliquez-moi le machine learning"}, {"role": "assistant", "content": "Le machine learning est une branche de l'IA qui permet aux ordinateurs d'apprendre..."}]}
```

### Structure

- **Fichier** : Format JSONL (une ligne = un dialogue)
- **ClÃ© `messages`** : Liste de messages alternant `user` et `assistant`
- **Encodage** : UTF-8

### Exemple de dataset minimal

CrÃ©ez un fichier `example_dataset.jsonl` :

```jsonl
{"messages": [{"role": "user", "content": "Qui est Victor Hugo ?"}, {"role": "assistant", "content": "Victor Hugo (1802-1885) est un Ã©crivain franÃ§ais majeur du XIXe siÃ¨cle, auteur des MisÃ©rables et de Notre-Dame de Paris."}]}
{"messages": [{"role": "user", "content": "Quelle est la capitale de la France ?"}, {"role": "assistant", "content": "La capitale de la France est Paris."}]}
{"messages": [{"role": "user", "content": "Comment faire une omelette ?"}, {"role": "assistant", "content": "Pour faire une omelette : battez 2-3 Å“ufs, ajoutez sel et poivre, versez dans une poÃªle chaude avec du beurre, laissez cuire 2-3 minutes."}]}
```

> **Note** : Pour de bons rÃ©sultats, visez **200+ dialogues** de qualitÃ©.

## ğŸ“ Structure du projet

```
nanochat-french-tutorial/
â”œâ”€â”€ nanochat_french_colab.ipynb  # Le notebook principal
â”œâ”€â”€ README.md                     # Ce fichier
â”œâ”€â”€ examples/                     # Exemples de datasets
â”‚   â””â”€â”€ example_dataset.jsonl
â””â”€â”€ .gitignore
```

## ğŸ“ Ce que vous apprendrez

En suivant ce tutorial, vous dÃ©couvrirez :

1. **Fine-tuning de LLMs** : Comment adapter un modÃ¨le prÃ©-entraÃ®nÃ© Ã  votre cas d'usage
2. **GPT-2 Architecture** : Comprendre le modÃ¨le GPT-2 franÃ§ais
3. **Google Colab** : Utiliser des GPUs gratuits pour l'entraÃ®nement
4. **Dataset preparation** : Formater vos donnÃ©es pour l'entraÃ®nement
5. **Ã‰valuation** : Tester et valider votre modÃ¨le fine-tunÃ©
6. **DÃ©ploiement** : TÃ©lÃ©charger et utiliser votre modÃ¨le localement

## âš™ï¸ ParamÃ¨tres d'entraÃ®nement

Les paramÃ¨tres par dÃ©faut sont optimisÃ©s pour un bon compromis qualitÃ©/temps :

| ParamÃ¨tre | Valeur | Description |
|-----------|--------|-------------|
| `NUM_EPOCHS` | 3 | Nombre de passages sur le dataset |
| `DEVICE_BATCH_SIZE` | 32 | Nombre d'exemples par batch |
| `EMBEDDING_LR` | 0.2 | Learning rate pour les embeddings |
| `MATRIX_LR` | 0.02 | Learning rate pour les matrices |

Ces paramÃ¨tres peuvent Ãªtre modifiÃ©s dans la cellule "Configuration" du notebook.

## ğŸ“Š Performances attendues

Sur un GPU T4 gratuit (Google Colab) :

- **Temps d'installation** : 2-3 minutes
- **Temps de training** (300 iterations) : 10-15 minutes
- **Taille du modÃ¨le** : ~1.7 GB
- **CoÃ»t** : 0â‚¬ (GPU gratuit)

ComparÃ© Ã  un CPU (MacBook Pro) :
- Training sur CPU : **60+ heures** âŒ
- Training sur T4 GPU : **10 minutes** âœ…

C'est **360Ã— plus rapide** ! ğŸš€

## ğŸ› ï¸ Technologies utilisÃ©es

- [Nanochat](https://github.com/keller-jordan/nanochat) - Framework de training LLM minimaliste
- [GPT-2 French](https://huggingface.co/asi/gpt-fr-cased-base) - ModÃ¨le de base prÃ©-entraÃ®nÃ©
- [Google Colab](https://colab.research.google.com/) - Environnement GPU gratuit
- [PyTorch](https://pytorch.org/) - Framework deep learning
- [Transformers](https://huggingface.co/transformers/) - BibliothÃ¨que Hugging Face

## ğŸ†˜ ProblÃ¨mes courants

### Le GPU n'est pas activÃ©
**Solution** : Runtime â†’ Change runtime type â†’ SÃ©lectionnez T4 GPU

### "Out of Memory" pendant le training
**Solution** : RÃ©duisez `DEVICE_BATCH_SIZE` de 32 Ã  16 ou 8

### Le modÃ¨le gÃ©nÃ¨re du charabia
**Solutions** :
- Augmentez le nombre d'Ã©poques (`NUM_EPOCHS = 5`)
- VÃ©rifiez la qualitÃ© de votre dataset
- Ajoutez plus d'exemples (200+ recommandÃ©)

### Erreur lors de l'upload du dataset
**Solution** : VÃ©rifiez que votre fichier est bien au format JSONL UTF-8

## ğŸ¤ Contribuer

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez ce repo
2. CrÃ©ez une branche (`git checkout -b feature/amÃ©lioration`)
3. Committez vos changements (`git commit -m 'Ajout d'une fonctionnalitÃ©'`)
4. Pushez (`git push origin feature/amÃ©lioration`)
5. Ouvrez une Pull Request

## ğŸ“š Ressources complÃ©mentaires

- [Documentation Nanochat](https://github.com/keller-jordan/nanochat)
- [GPT-2 Paper](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [Google Colab Tips](https://colab.research.google.com/notebooks/welcome.ipynb)

## ğŸ“„ Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

Le projet [Nanochat](https://github.com/keller-jordan/nanochat) original est Ã©galement sous licence MIT.

## ğŸ™ Remerciements

- [keller-jordan](https://github.com/keller-jordan) pour le framework Nanochat
- [asi](https://huggingface.co/asi) pour le modÃ¨le GPT-2 franÃ§ais prÃ©-entraÃ®nÃ©
- La communautÃ© Hugging Face pour les outils et modÃ¨les

## âœ¨ Exemples de rÃ©sultats

AprÃ¨s fine-tuning sur un dataset de 300 dialogues techniques :

**Avant (modÃ¨le de base)** :
```
Prompt: "Expliquez-moi le machine learning"
Sortie: "Le machine learning est un domaine de recherche..."
```

**AprÃ¨s (fine-tunÃ©)** :
```
Prompt: "Expliquez-moi le machine learning"
Sortie: "Le machine learning est une branche de l'intelligence artificielle
qui permet aux ordinateurs d'apprendre Ã  partir de donnÃ©es sans Ãªtre
explicitement programmÃ©s. Il repose sur des algorithmes qui identifient
des patterns dans les donnÃ©es et les utilisent pour faire des prÃ©dictions..."
```

---

**Made with â¤ï¸ for the French AI community**

Pour toute question, ouvrez une [issue](https://github.com/VOTRE-USERNAME/nanochat-french-tutorial/issues) !
